{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEpGkBAFzgMe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from catboost import CatBoostClassifier\n",
        "# from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import Lasso\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYpweRHOzro_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbyNJrZc0EAr",
        "outputId": "aa8a519c-4038-4d08-cb1b-bd5460e92d26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encounter_id                       0\n",
              "patient_id                         0\n",
              "hospital_id                        0\n",
              "age                             4228\n",
              "bmi                             3429\n",
              "                               ...  \n",
              "solid_tumor_with_metastasis      715\n",
              "apache_3j_bodysystem            1662\n",
              "apache_2_bodysystem             1662\n",
              "Unnamed: 83                    91713\n",
              "hospital_death                     0\n",
              "Length: 85, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2_uR6nQ1Vsl",
        "outputId": "7de5c57d-62c8-4e5f-e753-233ab51adc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 91713 entries, 0 to 91712\n",
            "Data columns (total 85 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   encounter_id                   91713 non-null  int64  \n",
            " 1   patient_id                     91713 non-null  int64  \n",
            " 2   hospital_id                    91713 non-null  int64  \n",
            " 3   age                            87485 non-null  float64\n",
            " 4   bmi                            88284 non-null  float64\n",
            " 5   elective_surgery               91713 non-null  int64  \n",
            " 6   ethnicity                      90318 non-null  object \n",
            " 7   gender                         91688 non-null  object \n",
            " 8   height                         90379 non-null  float64\n",
            " 9   icu_admit_source               91601 non-null  object \n",
            " 10  icu_id                         91713 non-null  int64  \n",
            " 11  icu_stay_type                  91713 non-null  object \n",
            " 12  icu_type                       91713 non-null  object \n",
            " 13  pre_icu_los_days               91713 non-null  float64\n",
            " 14  weight                         88993 non-null  float64\n",
            " 15  apache_2_diagnosis             90051 non-null  float64\n",
            " 16  apache_3j_diagnosis            90612 non-null  float64\n",
            " 17  apache_post_operative          91713 non-null  int64  \n",
            " 18  arf_apache                     90998 non-null  float64\n",
            " 19  gcs_eyes_apache                89812 non-null  float64\n",
            " 20  gcs_motor_apache               89812 non-null  float64\n",
            " 21  gcs_unable_apache              90676 non-null  float64\n",
            " 22  gcs_verbal_apache              89812 non-null  float64\n",
            " 23  heart_rate_apache              90835 non-null  float64\n",
            " 24  intubated_apache               90998 non-null  float64\n",
            " 25  map_apache                     90719 non-null  float64\n",
            " 26  resprate_apache                90479 non-null  float64\n",
            " 27  temp_apache                    87605 non-null  float64\n",
            " 28  ventilated_apache              90998 non-null  float64\n",
            " 29  d1_diasbp_max                  91548 non-null  float64\n",
            " 30  d1_diasbp_min                  91548 non-null  float64\n",
            " 31  d1_diasbp_noninvasive_max      90673 non-null  float64\n",
            " 32  d1_diasbp_noninvasive_min      90673 non-null  float64\n",
            " 33  d1_heartrate_max               91568 non-null  float64\n",
            " 34  d1_heartrate_min               91568 non-null  float64\n",
            " 35  d1_mbp_max                     91493 non-null  float64\n",
            " 36  d1_mbp_min                     91493 non-null  float64\n",
            " 37  d1_mbp_noninvasive_max         90234 non-null  float64\n",
            " 38  d1_mbp_noninvasive_min         90234 non-null  float64\n",
            " 39  d1_resprate_max                91328 non-null  float64\n",
            " 40  d1_resprate_min                91328 non-null  float64\n",
            " 41  d1_spo2_max                    91380 non-null  float64\n",
            " 42  d1_spo2_min                    91380 non-null  float64\n",
            " 43  d1_sysbp_max                   91554 non-null  float64\n",
            " 44  d1_sysbp_min                   91554 non-null  float64\n",
            " 45  d1_sysbp_noninvasive_max       90686 non-null  float64\n",
            " 46  d1_sysbp_noninvasive_min       90686 non-null  float64\n",
            " 47  d1_temp_max                    89389 non-null  float64\n",
            " 48  d1_temp_min                    89389 non-null  float64\n",
            " 49  h1_diasbp_max                  88094 non-null  float64\n",
            " 50  h1_diasbp_min                  88094 non-null  float64\n",
            " 51  h1_diasbp_noninvasive_max      84363 non-null  float64\n",
            " 52  h1_diasbp_noninvasive_min      84363 non-null  float64\n",
            " 53  h1_heartrate_max               88923 non-null  float64\n",
            " 54  h1_heartrate_min               88923 non-null  float64\n",
            " 55  h1_mbp_max                     87074 non-null  float64\n",
            " 56  h1_mbp_min                     87074 non-null  float64\n",
            " 57  h1_mbp_noninvasive_max         82629 non-null  float64\n",
            " 58  h1_mbp_noninvasive_min         82629 non-null  float64\n",
            " 59  h1_resprate_max                87356 non-null  float64\n",
            " 60  h1_resprate_min                87356 non-null  float64\n",
            " 61  h1_spo2_max                    87528 non-null  float64\n",
            " 62  h1_spo2_min                    87528 non-null  float64\n",
            " 63  h1_sysbp_max                   88102 non-null  float64\n",
            " 64  h1_sysbp_min                   88102 non-null  float64\n",
            " 65  h1_sysbp_noninvasive_max       84372 non-null  float64\n",
            " 66  h1_sysbp_noninvasive_min       84372 non-null  float64\n",
            " 67  d1_glucose_max                 85906 non-null  float64\n",
            " 68  d1_glucose_min                 85906 non-null  float64\n",
            " 69  d1_potassium_max               82128 non-null  float64\n",
            " 70  d1_potassium_min               82128 non-null  float64\n",
            " 71  apache_4a_hospital_death_prob  83766 non-null  float64\n",
            " 72  apache_4a_icu_death_prob       83766 non-null  float64\n",
            " 73  aids                           90998 non-null  float64\n",
            " 74  cirrhosis                      90998 non-null  float64\n",
            " 75  diabetes_mellitus              90998 non-null  float64\n",
            " 76  hepatic_failure                90998 non-null  float64\n",
            " 77  immunosuppression              90998 non-null  float64\n",
            " 78  leukemia                       90998 non-null  float64\n",
            " 79  lymphoma                       90998 non-null  float64\n",
            " 80  solid_tumor_with_metastasis    90998 non-null  float64\n",
            " 81  apache_3j_bodysystem           90051 non-null  object \n",
            " 82  apache_2_bodysystem            90051 non-null  object \n",
            " 83  Unnamed: 83                    0 non-null      float64\n",
            " 84  hospital_death                 91713 non-null  int64  \n",
            "dtypes: float64(71), int64(7), object(7)\n",
            "memory usage: 59.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuiKVRst1i3j"
      },
      "outputs": [],
      "source": [
        "df.drop([\"encounter_id\" ,\"patient_id\" ,\"hospital_id\",\"Unnamed: 83\", ],axis =1, inplace=True) # Not relevant to predict if a patient died or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdlqnDDn1kkn"
      },
      "outputs": [],
      "source": [
        "# Dealing with numerical columns\n",
        "Num=[]\n",
        "for col in df.columns:\n",
        "    if (df[col].dtype==int)or (df[col].dtype==float):\n",
        "        Num.append(col)\n",
        "\n",
        "\n",
        "for col in df.columns:\n",
        "    if col in Num :\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "        \n",
        "        \n",
        "# Dealing with categorical columns\n",
        "categorical=[]\n",
        "for col in df.columns:\n",
        "    if  (df[col].dtype==object):\n",
        "        categorical.append(col)\n",
        "\n",
        "for col in df.columns:\n",
        "    if col in categorical:\n",
        "        df[col].fillna(df[col].mode(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWZZ3WLb4KUz",
        "outputId": "2b46da64-49ef-4451-bc74-5c9121de594f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/72.4 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.7.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.21.6)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.5.1.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelling Section:"
      ],
      "metadata": {
        "id": "5TUbjPOPzLm1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BarcY5Ee3--X"
      },
      "outputs": [],
      "source": [
        "from category_encoders import CountEncoder\n",
        "CE = CountEncoder(normalize=True, cols=categorical)\n",
        "data = CE.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRyY_hDu4Q7T"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "RS = RobustScaler()\n",
        "scale = RS.fit_transform(data)\n",
        "data = pd.DataFrame(scale, columns=data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbaNI4W75JGC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 0: XG Boost, XG Boost with LDA & XG Boost with PCA ###"
      ],
      "metadata": {
        "id": "FGSXxz7bI4DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB \n",
        "\n",
        "model = xgb.XGBRegressor(seed = 20, objective = 'multi:softmax', \n",
        "           max_depth = 6,\n",
        "           learning_rate = 0.1,\n",
        "           subsample = 0.7,\n",
        "           colsample_bytree = 0.2,\n",
        "           colsample_bylevel = 0.5,\n",
        "           n_estimators = 100, num_class = 2)\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Acuracy of the xgboost{accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "vvoJO5L_JBL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB PCA\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply PCA with an explained_variance ratio of 0.7\n",
        "pca = PCA(n_components = 0.7)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "# Create the XGBoost model\n",
        "model = xgb.XGBRegressor(seed = 20, objective = 'multi:softmax', \n",
        "           max_depth = 6,\n",
        "           learning_rate = 0.1,\n",
        "           subsample = 0.7,\n",
        "           colsample_bytree = 0.2,\n",
        "           colsample_bylevel = 0.5,\n",
        "           n_estimators = 100, num_class = 2)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the xgboost: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "AoB1uYM2JRXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB LDA\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LDA\n",
        "lda = LDA()\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "# Create the XGBoost model\n",
        "model = xgb.XGBRegressor(seed = 20, objective = 'multi:softmax', \n",
        "           max_depth = 6,\n",
        "           learning_rate = 0.1,\n",
        "           subsample = 0.6,\n",
        "           colsample_bytree = 0.3,\n",
        "           colsample_bylevel = 0.5,\n",
        "           n_estimators = 100, num_class = 2)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the xgboost: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "v9As8-4UJTd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BernoulliNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the model\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "pred = bnb.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the BernoulliNB: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "5LhG6gZzJVxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BernoulliNB PCA\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=0.7)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "# Initialize the model\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Fit the model to the data\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred = bnb.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the BernoulliNB: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "E5X13qq4JXfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BernoulliNB LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LDA\n",
        "lda = LDA(n_components=1)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "# Initialize the model\n",
        "bnb = BernoulliNB(alpha = [1.0],\n",
        "              fit_prior = [True],\n",
        "              binarize = [1.0])\n",
        "\n",
        "# Fit the model to the data\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred = bnb.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the BernoulliNB: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "UWGRz_VnJZt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lightgbm \n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the model with the specified parameters\n",
        "lgbm = LGBMClassifier(learning_rate=0.01, n_estimators=1000, max_depth=9)\n",
        "\n",
        "# Fit the model to the training data\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "pred = lgbm.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the LGBMClassifier: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "-LCZ2BM8JcBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##lightgbm PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=0.7)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "# Initialize the model\n",
        "lgbm = LGBMClassifier(learning_rate=0.01, n_estimators=1000, max_depth=9)\n",
        "\n",
        "# Fit the model to the data\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred = lgbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the LGBMClassifier: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "HmD2korEJdq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lightgbm LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LDA\n",
        "lda = LDA(n_components=1)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "# Initialize the model\n",
        "lgbm = LGBMClassifier(learning_rate=0.01, n_estimators=1000, max_depth=9)\n",
        "\n",
        "# Fit the model to the data\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred = lgbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(f'Accuracy of the LGBMClassifier: {accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "HbgQTw0iJfXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1: Naive Bayes, KNN, Linear SVM, and SVM###"
      ],
      "metadata": {
        "id": "B4Cjesp37yKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "pred = classifier.predict(X_test)\n",
        "print(f'Acuracy of the Gaussian Naive Bayes:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "sO5suxwL7xuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "parameters = {'n_neighbors':list(range(20,31))}\n",
        "neigh = KNeighborsClassifier()\n",
        "clf = GridSearchCV(neigh, parameters)\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.best_params_)\n",
        "pred = clf.predict(X_test)\n",
        "print(f'Acuracy of the KNN{clf.best_params_}:{accuracy_score(y_test, pred)}')\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "# 16756 patients didn't die vs 1587 patients died\n",
        "# Out of all the players that the model predicted would die in hospital, only 75% actually did.\n",
        "# Out of all the patients that actually did die in the hospital, the model only predicted this outcome \n",
        "# correctly for 19% of those players\n",
        "# F1-score = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "# We are predicting accurately 0s but not ones"
      ],
      "metadata": {
        "id": "ZmPlzi5B8tMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=27)\n",
        "neigh.fit(X_train, y_train)\n",
        "pred = neigh.predict(X_test)\n",
        "print(f'Acuracy of the KNN27:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "# Cannot calculate feature importance in KNN"
      ],
      "metadata": {
        "id": "EQB4Ceqh8vNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM\n",
        "searcher = LinearSVC(penalty = 'l1', dual = False, max_iter = 10000)\n",
        "parameters = {'C': [0.01, 0.03, 0.05, 0.055, 0.06, 0.065, 0.07, 0.075]}\n",
        "searcher = GridSearchCV(searcher, parameters)\n",
        "searcher.fit(X_train, y_train)\n",
        "print(searcher.best_params_)\n",
        "pred = searcher.predict(X_test)\n",
        "print(f'Acuracy of the SVM{searcher.best_params_}:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "WhYAXz_a8wsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC(penalty = 'l1', dual = False, max_iter = 10000, C = 0.05)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "print(f'Acuracy of the SVM:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "# Calculate feature importance\n",
        "# importances = pd.DataFrame(data={\n",
        "#     'Attribute': X_train.columns,\n",
        "#     'Importance': svc.coef_[0]\n",
        "# })\n",
        "# importances = importances.sort_values(by='Importance', ascending=False)\n",
        "# plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
        "# plt.title('Feature importances obtained from coefficients', size=20)\n",
        "# plt.xticks(rotation='vertical')\n",
        "# plt.show()\n",
        "\n",
        "# I only want features with importance higher than 0.02\n",
        "# importances = importances[importances['Importance']>0.02]\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     data[importances['Attribute'].tolist()], data['hospital_death'], test_size=0.2, random_state=42)\n",
        "# This will not increase the recall of the model"
      ],
      "metadata": {
        "id": "4j6tYnO28yhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "# I tested all these kernels: linear, poly, rbf, sigmoid and the best one is sigmoid with C = 0.7\n",
        "svc = SVC(max_iter = -1, kernel = 'sigmoid', C = 0.7)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "print(f'Acuracy of the SVM:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "q-gG1RyX80AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2: KNN, Linear SVM and SVM with PCA ###"
      ],
      "metadata": {
        "id": "2geHK5nE83QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.7) # I tried 0.5 and 0.8, worser results\n",
        "X_train = pca.fit_transform(X_train, y_train)\n",
        "X_test = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "OWJYyzL181lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "parameters = {'n_neighbors':list(range(20,31))}\n",
        "neigh = KNeighborsClassifier()\n",
        "clf = GridSearchCV(neigh, parameters)\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.best_params_)\n",
        "pred = clf.predict(X_test)\n",
        "print(f'Acuracy of the KNN{clf.best_params_}:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "Kq_DJLGv85Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=29)\n",
        "neigh.fit(X_train, y_train)\n",
        "pred = neigh.predict(X_test)\n",
        "print(f'Acuracy of the KNN29:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred)) # recall is better, but still poor results"
      ],
      "metadata": {
        "id": "6J2lYPA786Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM\n",
        "svc = LinearSVC(penalty = 'l1', dual = False, max_iter = 10000, C = 1)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "print(f'Acuracy of the SVM:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "MZd8J2X49h9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "# I tested all these kernels: linear, poly, rbf, sigmoid and the best one is sigmoid with C = 0.7\n",
        "svc = SVC(max_iter = -1, kernel = 'sigmoid', C = 0.7)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "print(f'Acuracy of the SVM:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred)) # best result"
      ],
      "metadata": {
        "id": "hsb4T47Y9jqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3: KNN, Linear SVM and SVM with LDA ###"
      ],
      "metadata": {
        "id": "TdWl0XLK9mPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "lda = LDA(n_components=1)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)"
      ],
      "metadata": {
        "id": "J-toWZv59lAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "parameters = {'n_neighbors':list(range(20,31))}\n",
        "neigh = KNeighborsClassifier()\n",
        "clf = GridSearchCV(neigh, parameters)\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.best_params_)\n",
        "pred = clf.predict(X_test)\n",
        "print(f'Acuracy of the KNN{clf.best_params_}:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred)) # PCA better than LDA in KNN"
      ],
      "metadata": {
        "id": "4iLM134I-GFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=24)\n",
        "neigh.fit(X_train, y_train)\n",
        "pred = neigh.predict(X_test)\n",
        "print(f'Acuracy of the KNN24:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred)) # recall is better, but still poor results"
      ],
      "metadata": {
        "id": "i15lzP6i-HQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM\n",
        "svc = LinearSVC(penalty = 'l1', dual = False, max_iter = 10000, C = 1)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "print(f'Acuracy of the SVM:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred)) # best result"
      ],
      "metadata": {
        "id": "muN1YrXD-Ir0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "# I tested all these kernels: linear, poly, rbf, sigmoid and the best one is rbf with C=0.5\n",
        "svc = SVC(max_iter = -1, kernel = 'rbf', C=0.5)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "print(f'Acuracy of the SVM:{accuracy_score(y_test, pred)}')\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "GzchVJb1-J_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4: Random Forest Implementation ###\n"
      ],
      "metadata": {
        "id": "FUEB641XyM8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAgKBtRrnxWU",
        "outputId": "1c53a825-75bc-44dc-e102-f13e5e52cde1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.99      0.96     16756\n",
            "         1.0       0.69      0.26      0.38      1587\n",
            "\n",
            "    accuracy                           0.93     18343\n",
            "   macro avg       0.81      0.62      0.67     18343\n",
            "weighted avg       0.91      0.93      0.91     18343\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random forest implementation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNLJaRUcnxWU",
        "outputId": "c73ed1bf-5f90-47d8-d5b9-86b799e2d1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 15, 20, 25, 30],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 800, 1400, 2000]}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import pprint \n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 4)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 30, num = 5)]\n",
        "# max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "pp = pprint.PrettyPrinter(width=41, compact=True)\n",
        "pp.pprint(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a76V1OknxWV"
      },
      "outputs": [],
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMD-pF0lnxWV"
      },
      "outputs": [],
      "source": [
        "pred = rf_random.predict(X_test)\n",
        "print(rf_random.best_estimator_)\n",
        "print(classification_report(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5: Random Forest Implementation with LDA ###"
      ],
      "metadata": {
        "id": "qweWt0kMHSq3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEQ9mUV6nxWW"
      },
      "outputs": [],
      "source": [
        "# Running LDA\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "lda = LDA(n_components=1)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRi7yL1RnxWW",
        "outputId": "ed95b8bb-0548-4113-d16e-e5ff9fc9e46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 15, 20, 25, 30],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 800, 1400, 2000]},\n",
              "                   random_state=42, verbose=2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXeZCEBunxWX",
        "outputId": "bc1d718a-dbb6-4ea1-bf0b-c437baf7e50e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=1400)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.99      0.96     16756\n",
            "         1.0       0.62      0.22      0.33      1587\n",
            "\n",
            "    accuracy                           0.92     18343\n",
            "   macro avg       0.78      0.61      0.64     18343\n",
            "weighted avg       0.90      0.92      0.90     18343\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = rf_random.predict(X_test)\n",
        "print(rf_random.best_estimator_)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 6: Random Forest Implementation with PCA ###"
      ],
      "metadata": {
        "id": "xTBrC4crHbqz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvw5GpgZnxWX"
      },
      "outputs": [],
      "source": [
        "# Running PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(['hospital_death'],axis = 1), data['hospital_death'], test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.7) # I tried 0.5 and 0.8, worser results\n",
        "X_train = pca.fit_transform(X_train, y_train)\n",
        "X_test = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFEMHyYAnxWY",
        "outputId": "7bd635bf-44f6-4c02-9a91-8c0ec09a140f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 15, 20, 25, 30],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 800, 1400, 2000]},\n",
              "                   random_state=42, verbose=2)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYM2AQ3ZnxWY",
        "outputId": "7b81b3ac-29c1-45bf-fdcc-9f083aafd7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=1400)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.99      0.96     16756\n",
            "         1.0       0.67      0.25      0.36      1587\n",
            "\n",
            "    accuracy                           0.92     18343\n",
            "   macro avg       0.80      0.62      0.66     18343\n",
            "weighted avg       0.91      0.92      0.91     18343\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = rf_random.predict(X_test)\n",
        "print(rf_random.best_estimator_)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Section 7: Naive Bayes, Logistic Regression and Decision Tree###"
      ],
      "metadata": {
        "id": "9c3CwPL0yhv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Preprocessing to Encode Categorical Features ###"
      ],
      "metadata": {
        "id": "H7TLnlN80mXA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx-4qGFwnxWZ"
      },
      "outputs": [],
      "source": [
        "# 1. Encode ethnicity, gender, icu_admit_source, icu_stay_type, icu_type, apache_2_bodysystem:\n",
        "df = pd.concat([df,pd.get_dummies(df['ethnicity'], prefix='ethnic')],axis=1)\n",
        "df = pd.concat([df,pd.get_dummies(df['gender'], prefix='gender')],axis=1)\n",
        "df = pd.concat([df,pd.get_dummies(df['icu_admit_source'], prefix='admit_source')],axis=1)\n",
        "df = pd.concat([df,pd.get_dummies(df['icu_stay_type'], prefix='stay_type')],axis=1)\n",
        "df = pd.concat([df,pd.get_dummies(df['icu_type'], prefix='icu_type')],axis=1)\n",
        "df = pd.concat([df,pd.get_dummies(df['apache_2_bodysystem'], prefix='ap2bodsys')],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Drop ethnicity, gender, icu_admit_source, icu_stay_type, icu_type, apache_2_bodysystem and apache_3j_bodysystem:\n",
        "df.drop(['ethnicity'],axis=1, inplace=True)\n",
        "df.drop(['gender'],axis=1, inplace=True)\n",
        "df.drop(['icu_admit_source'],axis=1, inplace=True)\n",
        "df.drop(['icu_stay_type'],axis=1, inplace=True)\n",
        "df.drop(['icu_type'],axis=1, inplace=True)\n",
        "df.drop(['apache_2_bodysystem'], axis=1, inplace=True)\n",
        "df.drop(['apache_3j_bodysystem'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "qZl6SQzLz99X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['life_or_death'] = df['hospital_death'].values\n",
        "df.drop(['hospital_death'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "3Vgl3QeL0AG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Splitting into Training and Test Sets ###"
      ],
      "metadata": {
        "id": "F_X6Ez3L0wWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select X and y values:\n",
        "\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "-BNG-5OH0Fbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into training and testset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "nQPns46s0Gya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "bzrY1bJe0JM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Base Models (Naïve Bayes, Logistic and Decision Tree)"
      ],
      "metadata": {
        "id": "0B26ebZk0MHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## PART 1 ############\n",
        "##############################\n",
        "\n",
        "##############################\n",
        "########## Model 1: ##########\n",
        "\n",
        "# Training Naive Bayes Model\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0NEZdJj0LHr",
        "outputId": "561567e1-3926-4581-b39c-06e97262021f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score & Confusion Matrix for Naive Bayes Model \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUjT9TSQ0Qzn",
        "outputId": "f36705a3-8fc7-46ef-d8b8-2c59ce390bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13997  2675]\n",
            " [  556  1115]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8238565120209345"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Naive Bayes Model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wElXEtyv0bAw",
        "outputId": "4f902f75-b7eb-418a-a64b-ce5b99a8a4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.84      0.90     16672\n",
            "           1       0.29      0.67      0.41      1671\n",
            "\n",
            "    accuracy                           0.82     18343\n",
            "   macro avg       0.63      0.75      0.65     18343\n",
            "weighted avg       0.90      0.82      0.85     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 2: ##########\n",
        "\n",
        "# Training Logistic Regression Model on Training Set\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0, max_iter = 300)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLrNbPsD0eiJ",
        "outputId": "561cd26b-bb05-4595-8244-04da94a0e519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=300, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZDBY73L1b2R",
        "outputId": "887e4640-31b3-4768-eb89-1aa0d26f48c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score & Confusion Matrix for Logistic Regression \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir_OI0qU1g3k",
        "outputId": "0847e736-dd61-4ac7-d47e-25ed7c00cf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16468   204]\n",
            " [ 1242   429]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9211688382489233"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Logistic Regression\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6XmWlkS1jsQ",
        "outputId": "f40b9df5-2c16-4333-b522-b8b10dec54f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96     16672\n",
            "           1       0.68      0.26      0.37      1671\n",
            "\n",
            "    accuracy                           0.92     18343\n",
            "   macro avg       0.80      0.62      0.67     18343\n",
            "weighted avg       0.91      0.92      0.90     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 3: ##########\n",
        "\n",
        "# Training Decision Tree Model on Training Set\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkgikOW-1mKm",
        "outputId": "b315967b-fb97-46ab-b729-a0a50610c5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EqTLvBC1qcT",
        "outputId": "2cae953f-d439-44ae-e883-a0570d3b30fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15541  1131]\n",
            " [ 1083   588]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.879300005451671"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Decision Tree\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqfr5NHD1sCp",
        "outputId": "02320dc1-8874-4b65-9ea7-24735fe63391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93     16672\n",
            "           1       0.34      0.35      0.35      1671\n",
            "\n",
            "    accuracy                           0.88     18343\n",
            "   macro avg       0.64      0.64      0.64     18343\n",
            "weighted avg       0.88      0.88      0.88     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Section 8: Naive Bayes, Logistic Regression and Decision Tree with PCA ###"
      ],
      "metadata": {
        "id": "gxmKW_52136F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## PART 2 ############\n",
        "##############################\n",
        "\n",
        "# 1. Select X and y values:\n",
        "\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "\n",
        "# 2. Splitting dataset into training and testset:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# 3. Execute PCA:\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 0.7)\n",
        "X_train = pca.fit_transform(X_train, y_train)\n",
        "X_test = pca.transform(X_test)\n"
      ],
      "metadata": {
        "id": "U6VzUX5i1vdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 1: ##########\n",
        "\n",
        "# Training Naive Bayes Model\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3W6BIfF19O7",
        "outputId": "adca5602-f50b-43eb-9293-63d7b582ce55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score & Confusion Matrix for Naive Bayes Model \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o2EGWGD1_l-",
        "outputId": "f5af8f68-aa34-411d-a55e-498f10a8b30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13997  2675]\n",
            " [  556  1115]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8238565120209345"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Naive Bayes Model\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxphZqo22CBZ",
        "outputId": "c457dcb1-074c-422f-97e8-a48385c1ba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.84      0.90     16672\n",
            "           1       0.29      0.67      0.41      1671\n",
            "\n",
            "    accuracy                           0.82     18343\n",
            "   macro avg       0.63      0.75      0.65     18343\n",
            "weighted avg       0.90      0.82      0.85     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 2: ##########\n",
        "\n",
        "# Training Logistic Model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0, max_iter = 300)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqRX5qUH2ECK",
        "outputId": "0edeb549-58fb-4264-a6db-9722addb6157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=300, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Logistic Regression:\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD5pFw8h2GKq",
        "outputId": "3e082583-cab0-4097-b11c-a507cceccaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score & Confusion Matrix for Logistic Regression \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odiRIWmB2JYh",
        "outputId": "9eaa2adc-8dc3-4f0a-bc99-0db4495703d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16468   204]\n",
            " [ 1242   429]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9211688382489233"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Logistic Regression\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMYQ3n082Mn3",
        "outputId": "1626c429-517a-4fad-da5f-369a6fbcc6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96     16672\n",
            "           1       0.68      0.26      0.37      1671\n",
            "\n",
            "    accuracy                           0.92     18343\n",
            "   macro avg       0.80      0.62      0.67     18343\n",
            "weighted avg       0.91      0.92      0.90     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 3: ##########\n",
        "\n",
        "# Training Decision Tree Model on Training Set\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgtGGxxh2RcV",
        "outputId": "e01121b0-dcab-428a-85cc-981ea7ff462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Hmzk9z2TnO",
        "outputId": "465156cb-af61-4bf8-99b6-9f1f96c965af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15541  1131]\n",
            " [ 1083   588]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.879300005451671"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Decision Tree\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Rtelch2WJq",
        "outputId": "9fce2d50-43fc-4fcd-a7db-0b4b8ddd8840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93     16672\n",
            "           1       0.34      0.35      0.35      1671\n",
            "\n",
            "    accuracy                           0.88     18343\n",
            "   macro avg       0.64      0.64      0.64     18343\n",
            "weighted avg       0.88      0.88      0.88     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 9: Naive Bayes, Logistic Regression and Decision Tree with LDA ###"
      ],
      "metadata": {
        "id": "XiLsanqW2ZTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## PART 3 ############\n",
        "##############################\n",
        "\n",
        "# 1. Select X and y values:\n",
        "\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "\n",
        "# 2. Splitting dataset into training and testset:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# 3. Execute LDA:\n",
        "\n",
        "lda = LDA(n_components=1)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)"
      ],
      "metadata": {
        "id": "3xrQ-y4K2YI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 1: ##########\n",
        "\n",
        "# Training Naive Bayes Model\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9SMo5ew2hA0",
        "outputId": "9692dad3-0d37-40d8-9b87-8dd88fc6e183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score & Confusion Matrix for Naive Bayes Model \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZWw1yd32ik_",
        "outputId": "724e36ed-8408-4912-f707-51b95f7ab60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16252   420]\n",
            " [ 1078   593]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9183339693616094"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Naive Bayes Model\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NqDfEQH2lyK",
        "outputId": "2774b371-7b7c-4f12-af7e-f3584fef5e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96     16672\n",
            "           1       0.59      0.35      0.44      1671\n",
            "\n",
            "    accuracy                           0.92     18343\n",
            "   macro avg       0.76      0.66      0.70     18343\n",
            "weighted avg       0.91      0.92      0.91     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 2: ##########\n",
        "\n",
        "# Training Logistic Model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0, max_iter = 300)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkXdSA7D2n0G",
        "outputId": "4811da20-58c3-4ed2-cb89-39bdc26104e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=300, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Logistic Regression:\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGVf0nAW2p30",
        "outputId": "671463ee-9903-4ee5-eae9-47948a149967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Score & Confusion Matrix for Logistic Regression \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnLBPAaT2sLE",
        "outputId": "8f4fb436-8c0e-4211-f0a3-672bb4cf87df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16474   198]\n",
            " [ 1243   428]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9214414217957804"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report for Logistic Regression\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4OP7cxh2uOW",
        "outputId": "303b8a25-205a-4e39-9221-ace62d27da60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96     16672\n",
            "           1       0.68      0.26      0.37      1671\n",
            "\n",
            "    accuracy                           0.92     18343\n",
            "   macro avg       0.81      0.62      0.67     18343\n",
            "weighted avg       0.91      0.92      0.90     18343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "########## Model 3: ##########\n",
        "\n",
        "# Training Decision Tree Model on Training Set\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZK5ap-K2wGX",
        "outputId": "d36fa6c9-f8b8-4af2-b5df-b0f1e775d87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0wmdltA2x8x",
        "outputId": "87d66f5c-ff78-415c-9b1c-6b52112c64df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15592  1080]\n",
            " [ 1164   507]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8776645041705282"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEtB7nWU26jd",
        "outputId": "a133016b-5cb1-4f59-962c-a2613b1e9928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15592  1080]\n",
            " [ 1164   507]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8776645041705282"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5UuXLZaYIM4S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51W8l7CAIKId"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}